"""
íŒŒì¼ ë²„ì „ ê´€ë¦¬ ëª¨ë“ˆ: íŒŒì¼ëª… ìœ ì‚¬ì„± ë° ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ë²„ì „ ê·¸ë£¹í™”
"""

import re
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from dataclasses import dataclass, field
from collections import defaultdict
from difflib import SequenceMatcher
from datetime import datetime

from .config import OrganizerConfig
from .duplicate_finder import FileInfo

try:
    import ssdeep
    SSDEEP_AVAILABLE = True
except ImportError:
    SSDEEP_AVAILABLE = False


@dataclass
class VersionGroup:
    """ë™ì¼ ë¬¸ì„œì˜ ë²„ì „ ê·¸ë£¹"""
    base_name: str  # ê¸°ì¤€ íŒŒì¼ëª… (ë²„ì „ ì •ë³´ ì œê±°)
    files: List[FileInfo] = field(default_factory=list)
    extension: str = ""

    def add_file(self, file_info: FileInfo):
        """íŒŒì¼ ì¶”ê°€"""
        self.files.append(file_info)
        if not self.extension and file_info.path.suffix:
            self.extension = file_info.path.suffix

    def sort_by_date(self, newest_first: bool = True):
        """ìˆ˜ì •ì¼ ê¸°ì¤€ ì •ë ¬"""
        self.files.sort(key=lambda f: f.modified_time, reverse=newest_first)

    def get_latest(self) -> Optional[FileInfo]:
        """ê°€ì¥ ìµœì‹  íŒŒì¼ ë°˜í™˜"""
        if not self.files:
            return None
        self.sort_by_date(newest_first=True)
        return self.files[0]

    def get_oldest(self) -> Optional[FileInfo]:
        """ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ ë°˜í™˜"""
        if not self.files:
            return None
        self.sort_by_date(newest_first=False)
        return self.files[0]

    @property
    def count(self) -> int:
        """íŒŒì¼ ìˆ˜"""
        return len(self.files)


class VersionManager:
    """íŒŒì¼ ë²„ì „ ê´€ë¦¬ í´ë˜ìŠ¤"""

    # ë²„ì „ íŒ¨í„´ ì •ê·œì‹
    VERSION_PATTERNS = [
        # ìˆ«ì ë²„ì „: _v1, _v2, -v1, (1), [1]
        r'[_\-\s]?v(\d+)',
        r'\((\d+)\)',
        r'\[(\d+)\]',
        # ë‚ ì§œ ë²„ì „: _20231215, _2023-12-15
        r'[_\-](\d{8})',
        r'[_\-](\d{4}[-_]\d{2}[-_]\d{2})',
        # í•œê¸€ ë²„ì „ í‘œì‹œ
        r'[_\-\s]?(ìµœì¢…|final|ìˆ˜ì •|ìˆ˜ì •ë³¸|ì™„ë£Œ|ì™„ì„±)',
        r'[_\-\s]?(ì´ˆì•ˆ|draft|ì„ì‹œ|temp)',
        r'[_\-\s]?(ë°±ì—…|backup|bak)',
        r'[_\-\s]?(ë³µì‚¬ë³¸|copy|ì‚¬ë³¸)',
        # ì˜ë¬¸ ë²„ì „ í‘œì‹œ
        r'[_\-\s]?(old|new|latest|original)',
        r'[_\-\s]?(rev\d*|revision\d*)',
    ]

    # ì»´íŒŒì¼ëœ íŒ¨í„´
    COMPILED_PATTERNS = [re.compile(p, re.IGNORECASE) for p in VERSION_PATTERNS]

    def __init__(self, config: OrganizerConfig):
        self.config = config
        self._fuzzy_hash_cache: Dict[Path, str] = {}

    def _extract_base_name(self, filename: str) -> str:
        """
        íŒŒì¼ëª…ì—ì„œ ë²„ì „ ì •ë³´ë¥¼ ì œê±°í•˜ê³  ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ

        Args:
            filename: í™•ì¥ì ì œì™¸ íŒŒì¼ëª…

        Returns:
            ë²„ì „ ì •ë³´ê°€ ì œê±°ëœ ê¸°ë³¸ íŒŒì¼ëª…
        """
        base_name = filename

        # ëª¨ë“  ë²„ì „ íŒ¨í„´ ì œê±°
        for pattern in self.COMPILED_PATTERNS:
            base_name = pattern.sub('', base_name)

        # ì—°ì†ëœ êµ¬ë¶„ì ì •ë¦¬
        base_name = re.sub(r'[_\-\s]+', '_', base_name)
        base_name = base_name.strip('_- ')

        return base_name if base_name else filename

    def _calculate_similarity(self, name1: str, name2: str) -> float:
        """
        ë‘ íŒŒì¼ëª…ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)

        Args:
            name1: ì²« ë²ˆì§¸ íŒŒì¼ëª…
            name2: ë‘ ë²ˆì§¸ íŒŒì¼ëª…

        Returns:
            ìœ ì‚¬ë„ ì ìˆ˜
        """
        # ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ
        base1 = self._extract_base_name(name1).lower()
        base2 = self._extract_base_name(name2).lower()

        # SequenceMatcherë¡œ ìœ ì‚¬ë„ ê³„ì‚°
        return SequenceMatcher(None, base1, base2).ratio()

    def _has_version_indicator(self, filename: str) -> bool:
        """íŒŒì¼ëª…ì— ë²„ì „ í‘œì‹œê°€ ìˆëŠ”ì§€ í™•ì¸"""
        for pattern in self.COMPILED_PATTERNS:
            if pattern.search(filename):
                return True
        return False

    def _extract_version_info(self, filename: str) -> Dict:
        """
        íŒŒì¼ëª…ì—ì„œ ë²„ì „ ì •ë³´ ì¶”ì¶œ

        Args:
            filename: íŒŒì¼ëª…

        Returns:
            ë²„ì „ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        info = {
            'numeric_version': None,
            'date_version': None,
            'status': None,  # final, draft, backup ë“±
            'is_copy': False,
        }

        # ìˆ«ì ë²„ì „
        numeric_match = re.search(r'[_\-\s]?v(\d+)', filename, re.IGNORECASE)
        if numeric_match:
            info['numeric_version'] = int(numeric_match.group(1))

        # ê´„í˜¸ ì•ˆ ìˆ«ì
        paren_match = re.search(r'\((\d+)\)', filename)
        if paren_match and info['numeric_version'] is None:
            info['numeric_version'] = int(paren_match.group(1))

        # ë‚ ì§œ ë²„ì „
        date_match = re.search(r'(\d{4})[-_]?(\d{2})[-_]?(\d{2})', filename)
        if date_match:
            try:
                year, month, day = map(int, date_match.groups())
                if 1990 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:
                    info['date_version'] = f"{year}-{month:02d}-{day:02d}"
            except ValueError:
                pass

        # ìƒíƒœ í‘œì‹œ
        if re.search(r'(ìµœì¢…|final|ì™„ë£Œ|ì™„ì„±)', filename, re.IGNORECASE):
            info['status'] = 'final'
        elif re.search(r'(ì´ˆì•ˆ|draft|ì„ì‹œ|temp)', filename, re.IGNORECASE):
            info['status'] = 'draft'
        elif re.search(r'(ë°±ì—…|backup|bak)', filename, re.IGNORECASE):
            info['status'] = 'backup'

        # ë³µì‚¬ë³¸ ì—¬ë¶€
        if re.search(r'(ë³µì‚¬ë³¸|copy|ì‚¬ë³¸|\(\d+\))', filename, re.IGNORECASE):
            info['is_copy'] = True

        return info

    def _calculate_fuzzy_hash(self, file_path: Path) -> Optional[str]:
        """
        íŒŒì¼ì˜ ssdeep í¼ì§€ í•´ì‹œ ê³„ì‚°

        Args:
            file_path: íŒŒì¼ ê²½ë¡œ

        Returns:
            ssdeep í•´ì‹œ ë¬¸ìì—´ ë˜ëŠ” None (ì˜¤ë¥˜ ì‹œ)
        """
        if not SSDEEP_AVAILABLE:
            return None

        # ìºì‹œ í™•ì¸
        if file_path in self._fuzzy_hash_cache:
            return self._fuzzy_hash_cache[file_path]

        try:
            fuzzy_hash = ssdeep.hash_from_file(str(file_path))
            self._fuzzy_hash_cache[file_path] = fuzzy_hash
            return fuzzy_hash
        except (IOError, OSError, PermissionError):
            return None

    def _calculate_fuzzy_similarity(self, hash1: str, hash2: str) -> int:
        """
        ë‘ ssdeep í•´ì‹œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°

        Args:
            hash1: ì²« ë²ˆì§¸ ssdeep í•´ì‹œ
            hash2: ë‘ ë²ˆì§¸ ssdeep í•´ì‹œ

        Returns:
            ìœ ì‚¬ë„ ì ìˆ˜ (0-100)
        """
        if not SSDEEP_AVAILABLE or not hash1 or not hash2:
            return 0

        try:
            return ssdeep.compare(hash1, hash2)
        except Exception:
            return 0

    def find_version_groups(self, files: List[FileInfo]) -> List[VersionGroup]:
        """
        íŒŒì¼ ëª©ë¡ì—ì„œ ë²„ì „ ê·¸ë£¹ íƒì§€ (íŒŒì¼ëª… ìœ ì‚¬ë„ + ë‚´ìš© ìœ ì‚¬ë„ ê¸°ë°˜)

        Args:
            files: FileInfo ë¦¬ìŠ¤íŠ¸

        Returns:
            VersionGroup ë¦¬ìŠ¤íŠ¸
        """
        # í™•ì¥ìë³„ë¡œ ê·¸ë£¹í™”
        by_extension: Dict[str, List[FileInfo]] = defaultdict(list)
        for file_info in files:
            ext = file_info.path.suffix.lower()
            by_extension[ext].append(file_info)

        all_groups: List[VersionGroup] = []

        for ext, ext_files in by_extension.items():
            # 1ë‹¨ê³„: íŒŒì¼ëª… ìœ ì‚¬ë„ ê¸°ë°˜ ê·¸ë£¹í™”
            base_name_groups: Dict[str, List[FileInfo]] = defaultdict(list)

            for file_info in ext_files:
                stem = file_info.path.stem
                base_name = self._extract_base_name(stem)
                base_name_groups[base_name.lower()].append(file_info)

            # 2ê°œ ì´ìƒ íŒŒì¼ì´ ìˆëŠ” ê·¸ë£¹ë§Œ ì„ íƒ
            for base_name, group_files in base_name_groups.items():
                if len(group_files) > 1:
                    group = VersionGroup(base_name=base_name, extension=ext)
                    for f in group_files:
                        group.add_file(f)
                    group.sort_by_date(newest_first=True)
                    all_groups.append(group)

            # 2ë‹¨ê³„: ë‚´ìš© ìœ ì‚¬ë„ ê¸°ë°˜ ê·¸ë£¹í™” (ssdeep ì‚¬ìš©)
            if SSDEEP_AVAILABLE:
                content_groups = self._find_content_similar_groups(ext_files)
                all_groups.extend(content_groups)

        # ì¶”ê°€: ìœ ì‚¬ë„ ê¸°ë°˜ ê·¸ë£¹ ë³‘í•© ì‹œë„
        all_groups = self._merge_similar_groups(all_groups)

        return all_groups

    def _find_content_similar_groups(self, files: List[FileInfo]) -> List[VersionGroup]:
        """
        ë‚´ìš© ìœ ì‚¬ë„ ê¸°ë°˜ ë²„ì „ ê·¸ë£¹ íƒì§€ (ssdeep í¼ì§€ í•´ì‹±)

        Args:
            files: ê°™ì€ í™•ì¥ìì˜ íŒŒì¼ ëª©ë¡

        Returns:
            ë‚´ìš©ì´ ìœ ì‚¬í•œ íŒŒì¼ë“¤ì˜ ë²„ì „ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸
        """
        if not SSDEEP_AVAILABLE or len(files) < 2:
            return []

        # í¼ì§€ í•´ì‹œ ê³„ì‚°
        file_hashes: List[Tuple[FileInfo, str]] = []
        for file_info in files:
            fuzzy_hash = self._calculate_fuzzy_hash(file_info.path)
            if fuzzy_hash:
                file_hashes.append((file_info, fuzzy_hash))

        if len(file_hashes) < 2:
            return []

        # ë‚´ìš© ìœ ì‚¬ë„ ê¸°ë°˜ ê·¸ë£¹í™”
        content_groups: List[VersionGroup] = []
        used_indices = set()

        # ìœ ì‚¬ë„ ì„ê³„ê°’ (ì„¤ì • ê°€ëŠ¥, ê¸°ë³¸ 75% ìœ ì‚¬ë„)
        similarity_threshold = getattr(
            self.config,
            'content_similarity_threshold',
            75
        )

        for i, (file1, hash1) in enumerate(file_hashes):
            if i in used_indices:
                continue

            # ìƒˆ ê·¸ë£¹ ìƒì„±
            similar_files = [file1]
            used_indices.add(i)

            # ë‹¤ë¥¸ íŒŒì¼ë“¤ê³¼ ë¹„êµ
            for j, (file2, hash2) in enumerate(file_hashes):
                if j <= i or j in used_indices:
                    continue

                similarity = self._calculate_fuzzy_similarity(hash1, hash2)

                # ìœ ì‚¬ë„ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ ê°™ì€ ê·¸ë£¹
                if similarity >= similarity_threshold:
                    similar_files.append(file2)
                    used_indices.add(j)

            # 2ê°œ ì´ìƒ ìœ ì‚¬ íŒŒì¼ì´ ìˆìœ¼ë©´ ë²„ì „ ê·¸ë£¹ ìƒì„±
            if len(similar_files) > 1:
                # ê¸°ë³¸ ì´ë¦„ì€ ê°€ì¥ ìµœì‹  íŒŒì¼ì˜ ì´ë¦„ ì‚¬ìš©
                latest_file = max(similar_files, key=lambda f: f.modified_time)
                base_name = self._extract_base_name(latest_file.path.stem)

                group = VersionGroup(
                    base_name=f"{base_name}_content_similar",
                    extension=latest_file.path.suffix.lower()
                )

                for f in similar_files:
                    group.add_file(f)

                group.sort_by_date(newest_first=True)
                content_groups.append(group)

        return content_groups

    def _merge_similar_groups(self, groups: List[VersionGroup]) -> List[VersionGroup]:
        """
        ìœ ì‚¬í•œ ê¸°ë³¸ ì´ë¦„ì„ ê°€ì§„ ê·¸ë£¹ ë³‘í•©

        Args:
            groups: ë²„ì „ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë³‘í•©ëœ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸
        """
        if len(groups) <= 1:
            return groups

        merged = []
        used = set()

        for i, group1 in enumerate(groups):
            if i in used:
                continue

            current_group = VersionGroup(
                base_name=group1.base_name,
                extension=group1.extension
            )
            for f in group1.files:
                current_group.add_file(f)
            used.add(i)

            # ê°™ì€ í™•ì¥ìì˜ ë‹¤ë¥¸ ê·¸ë£¹ê³¼ ìœ ì‚¬ë„ ë¹„êµ
            for j, group2 in enumerate(groups):
                if j in used or j <= i:
                    continue
                if group1.extension != group2.extension:
                    continue

                similarity = self._calculate_similarity(
                    group1.base_name, group2.base_name
                )

                if similarity >= self.config.filename_similarity_threshold:
                    for f in group2.files:
                        current_group.add_file(f)
                    used.add(j)

            if current_group.count > 1:
                current_group.sort_by_date(newest_first=True)
                merged.append(current_group)

        return merged

    def analyze_version_group(self, group: VersionGroup) -> Dict:
        """
        ë²„ì „ ê·¸ë£¹ ë¶„ì„ ê²°ê³¼ ë°˜í™˜

        Args:
            group: ë¶„ì„í•  ë²„ì „ ê·¸ë£¹

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        group.sort_by_date(newest_first=True)

        analysis = {
            'base_name': group.base_name,
            'extension': group.extension,
            'total_files': group.count,
            'files': [],
            'recommended_keep': None,
            'recommended_archive': [],
        }

        final_version = None
        latest_version = group.files[0] if group.files else None

        for file_info in group.files:
            version_info = self._extract_version_info(file_info.path.stem)
            modified_date = datetime.fromtimestamp(file_info.modified_time)

            file_analysis = {
                'path': str(file_info.path),
                'filename': file_info.path.name,
                'size': file_info.size,
                'modified': modified_date.strftime('%Y-%m-%d %H:%M:%S'),
                'version_info': version_info,
            }
            analysis['files'].append(file_analysis)

            # 'final' ìƒíƒœ íŒŒì¼ ì°¾ê¸°
            if version_info['status'] == 'final':
                final_version = file_info

        # ë³´ì¡´ ì¶”ì²œ: final ë²„ì „ì´ ìˆìœ¼ë©´ ê·¸ê²ƒ, ì•„ë‹ˆë©´ ìµœì‹  íŒŒì¼
        if final_version:
            analysis['recommended_keep'] = str(final_version.path)
        elif latest_version:
            analysis['recommended_keep'] = str(latest_version.path)

        # ë‚˜ë¨¸ì§€ëŠ” ì•„ì¹´ì´ë¸Œ ì¶”ì²œ
        for file_info in group.files:
            if str(file_info.path) != analysis['recommended_keep']:
                analysis['recommended_archive'].append(str(file_info.path))

        return analysis

    def suggest_consolidation(self, groups: List[VersionGroup]) -> List[Dict]:
        """
        ë²„ì „ ê·¸ë£¹ë“¤ì— ëŒ€í•œ í†µí•© ì œì•ˆ

        Args:
            groups: ë²„ì „ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸

        Returns:
            í†µí•© ì œì•ˆ ë¦¬ìŠ¤íŠ¸
        """
        suggestions = []

        for group in groups:
            analysis = self.analyze_version_group(group)

            suggestion = {
                'group_info': {
                    'base_name': analysis['base_name'],
                    'extension': analysis['extension'],
                    'file_count': analysis['total_files'],
                },
                'keep': {
                    'path': analysis['recommended_keep'],
                    'reason': 'ê°€ì¥ ìµœì‹  ë²„ì „ ë˜ëŠ” ìµœì¢…ë³¸ìœ¼ë¡œ í‘œì‹œëœ íŒŒì¼'
                },
                'archive': [
                    {
                        'path': path,
                        'reason': 'ì´ì „ ë²„ì „ ë˜ëŠ” ë³µì‚¬ë³¸'
                    }
                    for path in analysis['recommended_archive']
                ],
                'files_detail': analysis['files'],
            }

            suggestions.append(suggestion)

        return suggestions


def format_version_report(groups: List[VersionGroup], manager: VersionManager) -> str:
    """
    ë²„ì „ ê·¸ë£¹ ë³´ê³ ì„œ í¬ë§·íŒ…

    Args:
        groups: ë²„ì „ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸
        manager: VersionManager ì¸ìŠ¤í„´ìŠ¤

    Returns:
        í¬ë§·ëœ ë³´ê³ ì„œ ë¬¸ìì—´
    """
    lines = []
    lines.append("=" * 60)
    lines.append("ğŸ“‹ íŒŒì¼ ë²„ì „ ë¶„ì„ ë³´ê³ ì„œ")
    lines.append("=" * 60)
    lines.append(f"\nì´ {len(groups)}ê°œì˜ ë²„ì „ ê·¸ë£¹ ë°œê²¬\n")

    for i, group in enumerate(groups, 1):
        analysis = manager.analyze_version_group(group)

        lines.append(f"\n{'â”€' * 50}")
        lines.append(f"ê·¸ë£¹ {i}: {analysis['base_name']}{analysis['extension']}")
        lines.append(f"íŒŒì¼ ìˆ˜: {analysis['total_files']}ê°œ")
        lines.append("")

        for j, file_detail in enumerate(analysis['files'], 1):
            is_keep = file_detail['path'] == analysis['recommended_keep']
            marker = "âœ“ [ë³´ì¡´ ì¶”ì²œ]" if is_keep else "  [ì•„ì¹´ì´ë¸Œ ì¶”ì²œ]"

            lines.append(f"  {j}. {file_detail['filename']}")
            lines.append(f"     {marker}")
            lines.append(f"     ìˆ˜ì •ì¼: {file_detail['modified']}")
            lines.append(f"     í¬ê¸°: {file_detail['size']:,} bytes")

            if file_detail['version_info']['status']:
                lines.append(f"     ìƒíƒœ: {file_detail['version_info']['status']}")
            lines.append("")

    lines.append("=" * 60)

    return "\n".join(lines)
